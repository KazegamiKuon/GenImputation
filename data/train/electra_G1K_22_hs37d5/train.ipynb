{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('GenImputation': conda)"
  },
  "interpreter": {
   "hash": "21eafac26cb0bf9ef9b8c25dccb1241681a8e30605e87a5c3f2fd922c9828120"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../../')\n",
    "from lib.data_processing import GenNLPMaskedDataset\n",
    "from transformers import ElectraForMaskedLM, ElectraTokenizer, ElectraConfig, TrainingArguments\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lib.utils import general as g\n",
    "from lib.config.config_class import page_config\n",
    "from lib.model.overwriter import OTrainingArguments, OTrainer\n",
    "from lib.utils.metrics import evalpred_to_word, r2_score_transformers\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "config = None\n",
    "with g.reading('/client/user1/cuongdev/GenImputation/data/train/electra_G1K_22_hs37d5/config.json') as cf:\n",
    "    config = json.load(cf)\n",
    "assert config is not None, \"config can't none\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "regions = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "batchs = [0,1,2,3,4,5,6,7,8]\n",
    "train_region_paths = page_config.get_file_paths(config[page_config.file_train_prefix],page_config.page,regions,batchs)\n",
    "test_region_paths = page_config.get_file_paths(config[page_config.file_test_prefix],page_config.page,regions,[0])\n",
    "vocab_file = config[page_config.vocab_file]\n",
    "save_dir = config[page_config.save_dir]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "training_args = OTrainingArguments(**config[page_config.train_args])\n",
    "output_dir = training_args.output_dir\n",
    "logging_dir = training_args.logging_dir\n",
    "modeling_args = ElectraConfig(**config[page_config.model_args])\n",
    "tokenizer = ElectraTokenizer(vocab_file=vocab_file)\n",
    "seed = training_args.seed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, region in enumerate(regions):\n",
    "    clear_output(wait=True)\n",
    "    save_path = save_dir.format(region)\n",
    "    prevert_path = save_dir.format(region-1)\n",
    "    ## Train and eval data\n",
    "    train_batch_paths = train_region_paths[i]\n",
    "    train_dataset = GenNLPMaskedDataset(\n",
    "        train_batch_paths[:-1],\n",
    "        tokenizer,\n",
    "        seed=seed,\n",
    "        masked_by_flag=True,\n",
    "        # masked_per=0.15,\n",
    "        only_input=True,\n",
    "        force_create=True)\n",
    "    eval_dataset = GenNLPMaskedDataset(train_batch_paths[-1:],tokenizer,seed=seed,masked_by_flag=True,only_input=True)\n",
    "    ## test data\n",
    "    test_batch_paths = test_region_paths[i]\n",
    "    test_dataset = GenNLPMaskedDataset(test_batch_paths,tokenizer,seed=seed,masked_by_flag=True,only_input=True)\n",
    "    ## model\n",
    "    modeling_args.vocab_size = tokenizer.vocab_size\n",
    "    modeling_args.max_position_embeddings = 1300\n",
    "    electra_model = ElectraForMaskedLM(modeling_args)\n",
    "    if os.path.isdir(prevert_path):\n",
    "        electra_model = ElectraForMaskedLM.from_pretrained(prevert_path)\n",
    "    training_args.output_dir = output_dir.format(region)\n",
    "    training_args.logging_dir = logging_dir.format(region)\n",
    "    trainer = OTrainer(\n",
    "        model = electra_model,\n",
    "        args=training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = eval_dataset,\n",
    "        compute_metrics = r2_score_transformers,\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(save_path)\n",
    "    output_test = trainer.predict(test_dataset)\n",
    "    metrics = output_test.metrics\n",
    "    test_result_path = os.path.join(save_path,'test_result.json')\n",
    "    with g.writing(test_result_path) as trf:\n",
    "        json.dump(metrics,trf)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run show r2 plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "true_data = []\n",
    "pred_data = []\n",
    "for i, region in enumerate(regions):\n",
    "    clear_output(wait=True)\n",
    "    ## Train and eval data\n",
    "    train_batch_paths = train_region_paths[i]\n",
    "    train_dataset = GenNLPMaskedDataset(\n",
    "        train_batch_paths[:-1],\n",
    "        tokenizer,\n",
    "        seed=seed,\n",
    "        masked_by_flag=True,\n",
    "        # masked_per=0.15,\n",
    "        only_input=True,\n",
    "        force_create=True)\n",
    "    eval_dataset = GenNLPMaskedDataset(train_batch_paths[-1:],tokenizer,seed=seed,masked_by_flag=True,only_input=True)\n",
    "    ## test data\n",
    "    test_batch_paths = test_region_paths[i]\n",
    "    test_dataset = GenNLPMaskedDataset(test_batch_paths,tokenizer,seed=seed,masked_by_flag=True,only_input=True,force_create=True)\n",
    "    ## model\n",
    "    modeling_args.vocab_size = tokenizer.vocab_size\n",
    "    modeling_args.max_position_embeddings = 2000\n",
    "    save_path = save_dir.format(region)\n",
    "    #Load model\n",
    "    electra_model = ElectraForMaskedLM.from_pretrained(save_path)\n",
    "    training_args.output_dir = output_dir.format(region)\n",
    "    training_args.logging_dir = logging_dir.format(region)\n",
    "    trainer = Trainer(\n",
    "        model = electra_model,\n",
    "        args=training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = eval_dataset,\n",
    "        compute_metrics = r2_score_transformers,\n",
    "    )\n",
    "    output_test = trainer.predict(test_dataset)\n",
    "    labels, top_word = logits_to_word(output_test)\n",
    "    true_data.append(labels)\n",
    "    pred_data.append(top_word)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "variant_ids = page_config.get_file_paths_in_dir('/client/user1/cuongdev/GenImputation/data/train/electra_G1K_22_hs37d5/corpus_dir/',page_config.variant)\n",
    "variant_ids.sort()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_origin = None\n",
    "for i, region in enumerate(regions):\n",
    "    temp = pd.read_csv(variant_ids[region],sep=page_config.page_split_params)\n",
    "    if df_origin is None:\n",
    "        df_origin = temp.copy()\n",
    "        \n",
    "    else:\n",
    "        df_origin = pd.concat([df_origin,temp])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "true_data = [d[:,1:-1] for d in true_data]\n",
    "pred_data = [d[:,1:-1] for d in pred_data]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_true = np.concatenate(true_data,axis=1)\n",
    "y_pred = np.concatenate(pred_data,axis=1)\n",
    "y_true.shape, y_pred.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from lib.data_processing import process_ouput as po"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "masked_indexs = df_origin['flag'].values == 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mafs = np.array(list(map(lambda af: af if af <= 0.5 else 1-af,df_origin['AF'].values)))\n",
    "mafs = mafs[masked_indexs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "po.plot_r2_by_maf(mafs,y_true.T[masked_indexs],[y_pred.T[masked_indexs]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "paper_format = '/client/user1/cuongdev/GenImputation/temp/chr22_{}.gen'\n",
    "paper_data = []\n",
    "for i, region in enumerate(regions):\n",
    "    paper_path = paper_format.format(region+1)\n",
    "    temp = pd.read_csv(paper_path,sep=' ',header=None)\n",
    "    temp.drop(columns=[0],inplace=True)\n",
    "    temp.rename(columns={1:'CHROM',2:'POS',3:'REF',4:'ALT'},inplace=True)\n",
    "    temp['CHROM'] = np.full(temp.shape[0],22)\n",
    "    paper_data.append(temp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "paper_r10 = pd.concat(paper_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cols = ['CHROM','POS','REF','ALT']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.merge(df_origin[cols],paper_r10,how='inner',on=cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_origin[cols].dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "paper_r10[cols].dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_origin"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "[pd.read_csv('/client/user1/cuongdev/GenImputation/data/train/electra_G1K_22_hs37d5/corpus_dir/G1K_22_hs37d5_biallelic_train.r00{:02d}.b0000.variant.gz'.format(i)).shape for i in range(20)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.read_csv('/client/user1/cuongdev/GenImputation/data/external/region_info/rnnimp.chr22.r0000.variant.gz')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.read_csv('/client/user1/cuongdev/GenImputation/data/train/electra_G1K_22_hs37d5/corpus_dir/G1K_22_hs37d5_biallelic_train.r0000.b0000.variant.gz')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}